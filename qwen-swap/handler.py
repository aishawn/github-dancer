import runpod
from runpod.serverless.utils import rp_upload
import os
import sys
import websocket
import base64
import json
import uuid
import logging
import urllib.request
import urllib.parse
import binascii # Base64 ì—ëŸ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ import
import subprocess
import time

# ë¡œê¹… ì„¤ì •ï¼ˆå¿…é¡»åœ¨å¯¼å…¥ ComfyUI ä¹‹å‰ï¼‰
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ==================== æ¶æ„è¯´æ˜ ====================
# 
# æ­£ç¡®æ–¹æ¡ˆï¼šä½¿ç”¨ API Prompt æ¨¡æ¿ï¼ˆComfyUI å®˜æ–¹æ¨èï¼‰
# 
# Step 1: åœ¨ UI é‡Œè°ƒé€š workflow
# Step 2: ç‚¹ Save â†’ å¯¼å‡º API æ ¼å¼ï¼ˆSave (API) / Copy APIï¼‰
# Step 3: ç”Ÿäº§ç¯å¢ƒåªåšã€Œå‚æ•°æ³¨å…¥ã€
# 
# ä¼˜åŠ¿ï¼š
# - è½¬æ¢é€»è¾‘ï¼š0ï¼ˆä¸éœ€è¦è½¬æ¢ï¼‰
# - GraphBuilder ä¾èµ–ï¼šä¸éœ€è¦
# - Custom node å…¼å®¹ï¼šUI å·²éªŒè¯
# - Debug æˆæœ¬ï¼šç›´è§‚
# - å¯ç»´æŠ¤æ€§ï¼šé«˜
# - ç¬¦åˆ ComfyUI è®¾è®¡ï¼šé¡ºç€æ¥
#

# CUDA ê²€ì‚¬ ë° ì„¤ì •
def check_cuda_availability():
    """CUDA ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ê³  í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    try:
        import torch
        if torch.cuda.is_available():
            logger.info("âœ… CUDA is available and working")
            os.environ['CUDA_VISIBLE_DEVICES'] = '0'
            return True
        else:
            logger.error("âŒ CUDA is not available")
            raise RuntimeError("CUDA is required but not available")
    except Exception as e:
        logger.error(f"âŒ CUDA check failed: {e}")
        raise RuntimeError(f"CUDA initialization failed: {e}")

# CUDA ê²€ì‚¬ ì‹¤í–‰
try:
    cuda_available = check_cuda_availability()
    if not cuda_available:
        raise RuntimeError("CUDA is not available")
except Exception as e:
    logger.error(f"Fatal error: {e}")
    logger.error("Exiting due to CUDA requirements not met")
    exit(1)



server_address = os.getenv('SERVER_ADDRESS', '127.0.0.1')
client_id = str(uuid.uuid4())
def save_data_if_base64(data_input, temp_dir, output_filename):
    """
    ì…ë ¥ ë°ì´í„°ê°€ Base64 ë¬¸ìì—´ì¸ì§€ í™•ì¸í•˜ê³ , ë§ë‹¤ë©´ íŒŒì¼ë¡œ ì €ì¥ í›„ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    ë§Œì•½ ì¼ë°˜ ê²½ë¡œ ë¬¸ìì—´ì´ë¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì…ë ¥ê°’ì´ ë¬¸ìì—´ì´ ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if not isinstance(data_input, str):
        return data_input

    try:
        # Base64 ë¬¸ìì—´ì€ ë””ì½”ë”©ì„ ì‹œë„í•˜ë©´ ì„±ê³µí•©ë‹ˆë‹¤.
        decoded_data = base64.b64decode(data_input)
        
        # ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ ìƒì„±
        os.makedirs(temp_dir, exist_ok=True)
        
        # ë””ì½”ë”©ì— ì„±ê³µí•˜ë©´, ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        with open(file_path, 'wb') as f: # ë°”ì´ë„ˆë¦¬ ì“°ê¸° ëª¨ë“œ('wb')ë¡œ ì €ì¥
            f.write(decoded_data)
        
        # ì €ì¥ëœ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        print(f"âœ… Base64 ì…ë ¥ì„ '{file_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        return file_path

    except (binascii.Error, ValueError):
        # ë””ì½”ë”©ì— ì‹¤íŒ¨í•˜ë©´, ì¼ë°˜ ê²½ë¡œë¡œ ê°„ì£¼í•˜ê³  ì›ë˜ ê°’ì„ ê·¸ëŒ€ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤.
        print(f"â¡ï¸ '{data_input}'ì€(ëŠ”) íŒŒì¼ ê²½ë¡œë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
        return data_input
    
def queue_prompt_via_http(prompt):
    """
    é€šè¿‡ HTTP /prompt API å‘é€ promptï¼ˆå›é€€æ–¹æ¡ˆï¼‰
    
    æ³¨æ„ï¼šè™½ç„¶ä½¿ç”¨ HTTP APIï¼Œä½†ä»ç„¶éµå¾ª"æ–¹æ¡ˆä¸€"åŸåˆ™ï¼š
    - åªåšå‚æ•°æ³¨å…¥ï¼Œä¸è½¬æ¢ workflow
    - ä½¿ç”¨ API Prompt æ¨¡æ¿
    """
    url = f"http://{server_address}:8188/prompt"
    logger.info(f"Queueing prompt via HTTP API: {url}")
    
    p = {"prompt": prompt, "client_id": client_id}
    data = json.dumps(p).encode('utf-8')
    req = urllib.request.Request(url, data=data)
    req.add_header('Content-Type', 'application/json')
    
    try:
        response = urllib.request.urlopen(req)
        result = json.loads(response.read())
        logger.info(f"âœ… Prompt queued via HTTP API, prompt_id: {result.get('prompt_id')}")
        return result
    except urllib.error.HTTPError as e:
        error_body = ""
        try:
            error_body = e.read().decode('utf-8')
        except:
            error_body = str(e)
        
        logger.error(f"HTTP Error {e.code}: {e.reason}")
        logger.error(f"Error response body: {error_body}")
        
        # å°è¯•è§£æé”™è¯¯ JSON
        try:
            error_json = json.loads(error_body)
            logger.error(f"Error JSON: {json.dumps(error_json, indent=2)}")
        except:
            pass
        
        raise Exception(f"ComfyUI API error ({e.code}): {error_body[:500]}") from e

def validate_and_fix_prompt(prompt):
    """
    éªŒè¯å’Œä¿®å¤ API Promptï¼ˆèŠ‚ç‚¹éªŒè¯ã€æ— æ•ˆèŠ‚ç‚¹ç§»é™¤ã€è°ƒåº¦å™¨ä¿®å¤ç­‰ï¼‰
    
    é‡è¦è¯´æ˜ï¼š
    - prompt å¿…é¡»æ˜¯ API æ ¼å¼ï¼š{node_id: {class_type, inputs}}
    - ä¸å†æ”¯æŒ UI æ ¼å¼è½¬æ¢
    - ä½¿ç”¨æ–¹å¼ï¼šåœ¨ ComfyUI UI ä¸­å¯¼å‡º API æ ¼å¼ï¼Œç„¶ååªåšå‚æ•°æ³¨å…¥
    """
    # è°ƒåº¦å™¨åç§°æ˜ å°„ï¼šå°†æ— æ•ˆçš„è°ƒåº¦å™¨åç§°æ˜ å°„åˆ°æœ‰æ•ˆçš„åç§°
    scheduler_name_mapping = {
        "beta57": "normal",  # beta57 å¯èƒ½ä¸è¢«æ”¯æŒï¼Œä½¿ç”¨ normal æ›¿ä»£
    }
    # éªŒè¯ prompt æ ¼å¼ï¼ˆå¿…é¡»æ˜¯ API æ ¼å¼ï¼‰
    if not isinstance(prompt, dict):
        raise ValueError(f"Prompt must be a dict (API format), got {type(prompt)}")
    
    # æ£€æŸ¥æ˜¯å¦æ˜¯ UI æ ¼å¼ï¼ˆæœ‰ nodes æ•°ç»„ï¼‰
    if "nodes" in prompt:
        raise ValueError(
            "UI format workflow is not supported. "
            "Please export API format from ComfyUI UI (Save â†’ API format), "
            "then use parameter injection only."
        )
    
    # éªŒè¯æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰ class_typeï¼Œå¹¶å¤„ç†æ— æ•ˆèŠ‚ç‚¹
    nodes_to_remove = []
    
    # å·²çŸ¥ä¸æ”¯æŒçš„èŠ‚ç‚¹ç±»å‹ï¼ˆå¯èƒ½æ˜¯è‡ªå®šä¹‰èŠ‚ç‚¹æœªå®‰è£…ï¼Œæˆ–å¯¼å‡ºé—®é¢˜ï¼‰
    # è¿™äº›èŠ‚ç‚¹ç±»å‹åœ¨ ComfyUI ä¸­å¯èƒ½ä¸å­˜åœ¨ï¼Œéœ€è¦ç§»é™¤
    unsupported_node_types = [
        "Sigmas Power",      # å¯èƒ½æ˜¯è‡ªå®šä¹‰èŠ‚ç‚¹ï¼Œå½“å‰ç¯å¢ƒæœªå®‰è£…
        "SigmasPreview",     # é¢„è§ˆèŠ‚ç‚¹ï¼Œç”¨äºè°ƒè¯•ï¼Œè¾“å‡ºæœªè¢«ä½¿ç”¨ï¼Œå¯ä»¥å®‰å…¨ç§»é™¤
    ]
    
    for node_id, node_data in prompt.items():
        # æ£€æŸ¥èŠ‚ç‚¹ ID æ˜¯å¦æœ‰æ•ˆ
        if not node_id or node_id == "#id" or not isinstance(node_id, str):
            logger.warning(f"Invalid node ID found: {node_id}, removing from prompt")
            nodes_to_remove.append(node_id)
            continue
        
        if not isinstance(node_data, dict):
            logger.warning(f"Node {node_id} is not a dict, removing from prompt")
            nodes_to_remove.append(node_id)
            continue
        
        # æ£€æŸ¥ class_type
        if "class_type" not in node_data:
            # æ£€æŸ¥æ˜¯å¦æœ‰ UNKNOWN å­—æ®µï¼ˆå¯¼å‡ºé—®é¢˜ï¼‰
            if "inputs" in node_data and "UNKNOWN" in node_data.get("inputs", {}):
                unknown_value = node_data["inputs"]["UNKNOWN"]
                logger.warning(f"Node {node_id} has UNKNOWN field: {unknown_value}")
                
                # å°è¯•ä¿®å¤ï¼šå¦‚æœæ˜¯ GGUF æ¨¡å‹æ–‡ä»¶ï¼Œè½¬æ¢ä¸º UNETLoader
                if isinstance(unknown_value, str) and unknown_value.endswith(".gguf"):
                    logger.info(f"Attempting to fix node {node_id}: converting UNKNOWN GGUF to UNETLoader")
                    # ä¿®å¤èŠ‚ç‚¹ï¼šæ·»åŠ  class_type å’Œæ­£ç¡®çš„ inputs
                    node_data["class_type"] = "UNETLoader"
                    # å°† GGUF æ–‡ä»¶åè½¬æ¢ä¸º safetensors æ–‡ä»¶å
                    # Qwen-Image-Edit-2509-Q8_0.gguf -> qwen_image_edit_2509_fp8_e4m3fn.safetensors
                    if "Qwen-Image-Edit-2509" in unknown_value:
                        node_data["inputs"] = {
                            "unet_name": "qwen_image_edit_2509_fp8_e4m3fn.safetensors",
                            "weight_dtype": "default"
                        }
                        logger.info(f"Fixed node {node_id}: UNETLoader with unet_name=qwen_image_edit_2509_fp8_e4m3fn.safetensors")
                    else:
                        # å…¶ä»– GGUF æ–‡ä»¶ï¼Œå°è¯•é€šç”¨è½¬æ¢
                        safetensors_name = unknown_value.replace(".gguf", ".safetensors").replace("-", "_").lower()
                        node_data["inputs"] = {
                            "unet_name": safetensors_name,
                            "weight_dtype": "default"
                        }
                        logger.warning(f"Fixed node {node_id} with guessed safetensors name: {safetensors_name}")
                else:
                    # æ— æ³•ä¿®å¤ï¼Œæ ‡è®°ä¸ºåˆ é™¤
                    logger.warning(f"Node {node_id} has UNKNOWN field but cannot be auto-fixed - removing from prompt. "
                                 f"This node may not be needed or needs to be fixed in the exported workflow.")
                    nodes_to_remove.append(node_id)
            else:
                raise ValueError(f"Node {node_id} missing required 'class_type' property")
        
        if "inputs" not in node_data:
            logger.warning(f"Node {node_id} missing 'inputs' property, removing from prompt")
            nodes_to_remove.append(node_id)
            continue
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯ä¸æ”¯æŒçš„èŠ‚ç‚¹ç±»å‹ï¼ˆå¯èƒ½æ˜¯è‡ªå®šä¹‰èŠ‚ç‚¹æœªå®‰è£…ï¼‰
        class_type = node_data.get("class_type", "")
        if class_type in unsupported_node_types:
            logger.warning(f"Node {node_id} has unsupported class_type '{class_type}' (may not be installed), removing from prompt")
            nodes_to_remove.append(node_id)
            continue
    
    # åœ¨åˆ é™¤èŠ‚ç‚¹å‰ï¼Œå…ˆä¿®å¤å¼•ç”¨ï¼ˆéœ€è¦è®¿é—®è¢«åˆ é™¤èŠ‚ç‚¹çš„ä¿¡æ¯ï¼‰
    # å¯¹äºæŸäº›èŠ‚ç‚¹ç±»å‹ï¼ˆå¦‚ Sigmas Powerï¼‰ï¼Œå¯ä»¥å°è¯•å°†å¼•ç”¨æ”¹ä¸ºå¼•ç”¨å…¶è¾“å…¥èŠ‚ç‚¹
    nodes_to_fix = {}  # {node_id: {input_key: new_reference}}
    for node_id, node_data in prompt.items():
        if "inputs" in node_data:
            for input_key, input_value in node_data["inputs"].items():
                # æ£€æŸ¥æ˜¯å¦æ˜¯èŠ‚ç‚¹å¼•ç”¨ [node_id, output_index]
                if isinstance(input_value, list) and len(input_value) >= 1:
                    referenced_node_id = str(input_value[0])
                    if referenced_node_id in nodes_to_remove:
                        removed_node = prompt.get(referenced_node_id)  # åœ¨åˆ é™¤å‰è·å–
                        if removed_node and removed_node.get("class_type") == "Sigmas Power":
                            # Sigmas Power èŠ‚ç‚¹ï¼šå°†å¼•ç”¨æ”¹ä¸ºå¼•ç”¨å…¶ sigmas è¾“å…¥
                            sigmas_input = removed_node.get("inputs", {}).get("sigmas")
                            if isinstance(sigmas_input, list) and len(sigmas_input) >= 1:
                                # sigmas è¾“å…¥é€šå¸¸æ˜¯ [source_node_id, output_index]
                                source_node_id = str(sigmas_input[0])
                                source_output_index = sigmas_input[1] if len(sigmas_input) > 1 else 0
                                # å¦‚æœæºèŠ‚ç‚¹è¿˜åœ¨ prompt ä¸­ï¼Œåˆ™æ›¿æ¢å¼•ç”¨
                                if source_node_id in prompt and source_node_id not in nodes_to_remove:
                                    if node_id not in nodes_to_fix:
                                        nodes_to_fix[node_id] = {}
                                    nodes_to_fix[node_id][input_key] = [source_node_id, source_output_index]
                                    logger.info(f"Will fix node {node_id} input '{input_key}': "
                                              f"change reference from removed node {referenced_node_id} "
                                              f"to {source_node_id} (Sigmas Power bypass)")
                                    continue
                        logger.warning(f"Node {node_id} input '{input_key}' references removed node {referenced_node_id}. "
                                     f"This may cause execution errors.")
    
    # åº”ç”¨ä¿®å¤
    for node_id, fixes in nodes_to_fix.items():
        if node_id in prompt:
            for input_key, new_reference in fixes.items():
                prompt[node_id]["inputs"][input_key] = new_reference
    
    # ç§»é™¤æ— æ•ˆèŠ‚ç‚¹
    for node_id in nodes_to_remove:
        del prompt[node_id]
        logger.info(f"Removed invalid node {node_id} from prompt")
    
    logger.info(f"âœ… Validated API format prompt with {len(prompt)} nodes (removed {len(nodes_to_remove)} invalid nodes)")
    
    # ä¿®å¤æ— æ•ˆçš„è°ƒåº¦å™¨å’Œé‡‡æ ·å™¨åç§°
    scheduler_name_mapping = {
        "beta57": "normal",  # beta57 å¯èƒ½ä¸è¢«æ”¯æŒï¼Œä½¿ç”¨ normal æ›¿ä»£
    }
    sampler_name_mapping = {
        "res_2s": "euler",  # res_2s å¯èƒ½ä¸è¢«æ”¯æŒï¼Œä½¿ç”¨ euler æ›¿ä»£
    }
    
    for node_id, node_data in prompt.items():
        if isinstance(node_data, dict) and "inputs" in node_data:
            inputs = node_data["inputs"]
            
            # ä¿®å¤è°ƒåº¦å™¨åç§°
            if "scheduler" in inputs:
                scheduler_name = inputs["scheduler"]
                if scheduler_name in scheduler_name_mapping:
                    new_scheduler = scheduler_name_mapping[scheduler_name]
                    inputs["scheduler"] = new_scheduler
                    logger.info(f"âœ… Fixed scheduler name in node {node_id}: {scheduler_name} -> {new_scheduler}")
            
            # ä¿®å¤é‡‡æ ·å™¨åç§°ï¼ˆKSamplerSelect èŠ‚ç‚¹ï¼‰
            if "sampler_name" in inputs:
                sampler_name = inputs["sampler_name"]
                if sampler_name in sampler_name_mapping:
                    new_sampler = sampler_name_mapping[sampler_name]
                    inputs["sampler_name"] = new_sampler
                    logger.info(f"âœ… Fixed sampler name in node {node_id}: {sampler_name} -> {new_sampler}")

def get_image(filename, subfolder, folder_type):
    url = f"http://{server_address}:8188/view"
    logger.info(f"Getting image from: {url}")
    data = {"filename": filename, "subfolder": subfolder, "type": folder_type}
    url_values = urllib.parse.urlencode(data)
    with urllib.request.urlopen(f"{url}?{url_values}") as response:
        return response.read()

def get_history(prompt_id):
    url = f"http://{server_address}:8188/history/{prompt_id}"
    logger.info(f"Getting history from: {url}")
    with urllib.request.urlopen(url) as response:
        return json.loads(response.read())

def get_images(ws, prompt):
    """
    æ‰§è¡Œ API Prompt å¹¶è·å–ç”Ÿæˆçš„å›¾ç‰‡
    ä½¿ç”¨ HTTP API å‘é€ promptï¼ŒWebSocket ä»…ç”¨äºç›‘å¬æ‰§è¡ŒçŠ¶æ€
    """
    # å…ˆéªŒè¯å’Œä¿®å¤ prompt
    validate_and_fix_prompt(prompt)
    
    # ä½¿ç”¨ HTTP API å‘é€ promptï¼ˆWebSocket å‘é€ä¸è¢«æ”¯æŒï¼‰
    prompt_id = queue_prompt_via_http(prompt)['prompt_id']
    output_images = {}
    max_wait = 300  # æœ€å¤šç­‰å¾… 5 åˆ†é’Ÿ
    start_time = time.time()
    
    while time.time() - start_time < max_wait:
        try:
            ws.settimeout(1.0)
            out = ws.recv()
            if isinstance(out, str):
                message = json.loads(out)
                msg_type = message.get('type')
                
                if msg_type == 'executing':
                    data = message.get('data', {})
                    if data.get('node') is None and data.get('prompt_id') == prompt_id:
                        logger.info("âœ… Workflow execution completed")
                        break
                elif msg_type == 'execution_error':
                    error_data = message.get('data', {})
                    error_msg = error_data.get('message', 'Unknown error')
                    error_node = error_data.get('node_id', 'unknown')
                    error_type = error_data.get('node_type', 'unknown')
                    logger.error(f"âŒ Execution error at node {error_node} ({error_type}): {error_msg}")
                    raise Exception(f"ComfyUI execution error (node {error_node}): {error_msg}")
                elif msg_type == 'execution_cached':
                    # æ‰§è¡Œè¢«ç¼“å­˜ï¼Œç»§ç»­ç­‰å¾…å®Œæˆ
                    logger.debug(f"Execution cached for prompt {prompt_id}")
                elif msg_type == 'status':
                    # çŠ¶æ€æ›´æ–°ï¼Œç»§ç»­ç­‰å¾…
                    logger.debug(f"Status update: {message.get('data', {})}")
                elif msg_type == 'progress':
                    # è¿›åº¦æ›´æ–°ï¼Œç»§ç»­ç­‰å¾…
                    logger.debug(f"Progress update: {message.get('data', {})}")
        except websocket.WebSocketTimeoutException:
            # è¶…æ—¶ç»§ç»­ç­‰å¾…
            elapsed = time.time() - start_time
            if int(elapsed) % 10 == 0:  # æ¯10ç§’è®°å½•ä¸€æ¬¡
                logger.info(f"Still waiting for execution to complete... ({int(elapsed)}s elapsed)")
            continue
        except Exception as e:
            if "timeout" in str(e).lower():
                continue
            # å¦‚æœæ˜¯æ‰§è¡Œé”™è¯¯ï¼Œå·²ç»åœ¨ä¸Šé¢çš„ execution_error å¤„ç†ä¸­æŠ›å‡º
            raise
    
    if time.time() - start_time >= max_wait:
        raise Exception(f"Workflow execution timeout after {max_wait}s")

    history = get_history(prompt_id)[prompt_id]
    for node_id in history['outputs']:
        node_output = history['outputs'][node_id]
        images_output = []
        if 'images' in node_output:
            for image in node_output['images']:
                image_data = get_image(image['filename'], image['subfolder'], image['type'])
                # bytes ê°ì²´ë¥¼ base64ë¡œ ì¸ì½”ë”©í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ ë³€í™˜
                if isinstance(image_data, bytes):
                    import base64
                    image_data = base64.b64encode(image_data).decode('utf-8')
                images_output.append(image_data)
        output_images[node_id] = images_output

    return output_images

def load_workflow(workflow_path):
    """
    åŠ è½½ API Prompt æ¨¡æ¿æ–‡ä»¶
    
    é‡è¦ï¼šåªæ”¯æŒ API æ ¼å¼ï¼Œä¸æ”¯æŒ UI æ ¼å¼
    - åœ¨ ComfyUI UI ä¸­ï¼šSave â†’ å¯¼å‡º API æ ¼å¼ï¼ˆSave (API) / Copy APIï¼‰
    - å¾—åˆ°çš„æ˜¯ï¼š{node_id: {class_type, inputs}} æ ¼å¼
    
    å¦‚æœé‡åˆ° UI æ ¼å¼ï¼Œä¼šæŠ›å‡ºé”™è¯¯æç¤ºç”¨æˆ·å¯¼å‡º API æ ¼å¼
    """
    if not os.path.exists(workflow_path):
        raise FileNotFoundError(f"Workflow file not found: {workflow_path}")
    logger.info(f"Loading API prompt template from: {workflow_path}")
    
    with open(workflow_path, 'r', encoding='utf-8') as file:
        prompt = json.load(file)
    
    # éªŒè¯æ ¼å¼ï¼šå¿…é¡»æ˜¯ API æ ¼å¼ï¼Œä¸èƒ½æ˜¯ UI æ ¼å¼
    if "nodes" in prompt:
        raise ValueError(
            f"UI format workflow is not supported. "
            f"Please export API format from ComfyUI UI:\n"
            f"  1. Open workflow in ComfyUI UI\n"
            f"  2. Click 'Save' â†’ Select 'Save (API)' or 'Copy API'\n"
            f"  3. Save the API format JSON file\n"
            f"  4. Use that file as the workflow template"
        )
    
    # éªŒè¯ API æ ¼å¼
    if not isinstance(prompt, dict):
        raise ValueError(f"Prompt must be a dict (API format), got {type(prompt)}")
    
    # éªŒè¯æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰å¿…éœ€çš„å­—æ®µ
    for node_id, node_data in prompt.items():
        if not isinstance(node_data, dict):
            raise ValueError(f"Node {node_id} must be a dict, got {type(node_data)}")
        if "class_type" not in node_data:
            # æŸäº›èŠ‚ç‚¹å¯èƒ½æ²¡æœ‰ class_typeï¼ˆå¦‚æœªæ­£ç¡®å¯¼å‡ºçš„èŠ‚ç‚¹ï¼‰
            # æ£€æŸ¥æ˜¯å¦æœ‰ UNKNOWN å­—æ®µï¼ˆè¿™é€šå¸¸æ˜¯å¯¼å‡ºé—®é¢˜ï¼‰
            if "inputs" in node_data and "UNKNOWN" in node_data.get("inputs", {}):
                logger.warning(f"Node {node_id} has UNKNOWN field - this may be an export issue. "
                             f"Node data: {json.dumps(node_data, indent=2)}")
                # ä¸æŠ›å‡ºé”™è¯¯ï¼Œä½†è®°å½•è­¦å‘Šï¼Œå…è®¸ç»§ç»­æ‰§è¡Œ
            else:
                raise ValueError(f"Node {node_id} missing required 'class_type' property")
        if "inputs" not in node_data:
            raise ValueError(f"Node {node_id} missing required 'inputs' property")
    
    logger.info(f"âœ… Loaded API prompt template with {len(prompt)} nodes")
    return prompt

# ------------------------------
# ì…ë ¥ ì²˜ë¦¬ ìœ í‹¸ (path/url/base64)
# ------------------------------
def process_input(input_data, temp_dir, output_filename, input_type):
    """ì…ë ¥ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ì—¬ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    - input_type: "path" | "url" | "base64"
    """
    if input_type == "path":
        logger.info(f"ğŸ“ ê²½ë¡œ ì…ë ¥ ì²˜ë¦¬: {input_data}")
        return input_data
    elif input_type == "url":
        logger.info(f"ğŸŒ URL ì…ë ¥ ì²˜ë¦¬: {input_data}")
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        return download_file_from_url(input_data, file_path)
    elif input_type == "base64":
        logger.info("ğŸ”¢ Base64 ì…ë ¥ ì²˜ë¦¬")
        return save_base64_to_file(input_data, temp_dir, output_filename)
    else:
        raise Exception(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ì…ë ¥ íƒ€ì…: {input_type}")

def download_file_from_url(url, output_path):
    """URLì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ëŠ” í•¨ìˆ˜"""
    try:
        result = subprocess.run([
            'wget', '-O', output_path, '--no-verbose', url
        ], capture_output=True, text=True)
        if result.returncode == 0:
            logger.info(f"âœ… URLì—ì„œ íŒŒì¼ì„ ì„±ê³µì ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí–ˆìŠµë‹ˆë‹¤: {url} -> {output_path}")
            return output_path
        else:
            logger.error(f"âŒ wget ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
            raise Exception(f"URL ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {result.stderr}")
    except subprocess.TimeoutExpired:
        logger.error("âŒ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
        raise Exception("ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì´ˆê³¼")
    except Exception as e:
        logger.error(f"âŒ ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise Exception(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

def save_base64_to_file(base64_data, temp_dir, output_filename):
    """Base64 ë°ì´í„°ë¥¼ íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜"""
    try:
        decoded_data = base64.b64decode(base64_data)
        os.makedirs(temp_dir, exist_ok=True)
        file_path = os.path.abspath(os.path.join(temp_dir, output_filename))
        with open(file_path, 'wb') as f:
            f.write(decoded_data)
        logger.info(f"âœ… Base64 ì…ë ¥ì„ '{file_path}' íŒŒì¼ë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        return file_path
    except (binascii.Error, ValueError) as e:
        logger.error(f"âŒ Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")
        raise Exception(f"Base64 ë””ì½”ë”© ì‹¤íŒ¨: {e}")

def handler(job):
    job_input = job.get("input", {})

    logger.info(f"Received job input: {job_input}")
    task_id = f"task_{uuid.uuid4()}"

    # ------------------------------
    # ì´ë¯¸ì§€ ì…ë ¥ ìˆ˜ì§‘ (1ê°œ ë˜ëŠ” 2ê°œ)
    # ì§€ì› í‚¤: image_path | image_url | image_base64
    #         image_path_2 | image_url_2 | image_base64_2
    # ------------------------------
    image1_path = None
    image2_path = None

    if "image_path" in job_input:
        image1_path = process_input(job_input["image_path"], task_id, "input_image_1.jpg", "path")
    elif "image_url" in job_input:
        image1_path = process_input(job_input["image_url"], task_id, "input_image_1.jpg", "url")
    elif "image_base64" in job_input:
        image1_path = process_input(job_input["image_base64"], task_id, "input_image_1.jpg", "base64")

    if "image_path_2" in job_input:
        image2_path = process_input(job_input["image_path_2"], task_id, "input_image_2.jpg", "path")
    elif "image_url_2" in job_input:
        image2_path = process_input(job_input["image_url_2"], task_id, "input_image_2.jpg", "url")
    elif "image_base64_2" in job_input:
        image2_path = process_input(job_input["image_base64_2"], task_id, "input_image_2.jpg", "base64")

    # ------------------------------
    # Workflow ì„ íƒ ë°åŠ è½½ API Prompt æ¨¡æ¿
    # ------------------------------
    workflow_type = job_input.get("workflow_type", "default")
    
    if workflow_type == "head_swap_v3":
        # Head Swap V3 workflow ì‚¬ìš©
        if not image2_path:
            return {"error": "Head Swap V3 workflow requires two images (body and face)"}
        # ä½¿ç”¨ API æ ¼å¼çš„ workflow æ–‡ä»¶
        workflow_path = "/Head_Swap_V3__api.json"
    else:
        # ê¸°ë³¸ workflow ì‚¬ìš©
        if image2_path:
            workflow_path = "/qwen_image_edit_2.json"
        else:
            workflow_path = "/qwen_image_edit_1.json"
    
    # åŠ è½½ API Prompt æ¨¡æ¿ï¼ˆå¿…é¡»æ˜¯ API æ ¼å¼ï¼‰
    prompt = load_workflow(workflow_path)
    
    logger.info("Head_Swap_V3__api")
    # ä½¿ç”¨ deepcopy é¿å…ä¿®æ”¹æ¨¡æ¿
    import copy
    prompt = copy.deepcopy(prompt)
    
    # ------------------------------
    # ä¿®å¤æ¨¡å‹è·¯å¾„å’ŒèŠ‚ç‚¹ï¼ˆå¤„ç† Dockerfile ä¸­çš„å®é™…æ–‡ä»¶è·¯å¾„ + UNKNOWN èŠ‚ç‚¹ï¼‰
    # ------------------------------
    def fix_model_paths_and_nodes(prompt_data):
        """
        ä¿®å¤æ¨¡å‹è·¯å¾„å’ŒèŠ‚ç‚¹é—®é¢˜ï¼š
        1. ä¿®å¤ LoRA è·¯å¾„æ˜ å°„ï¼ˆworkflow è·¯å¾„ -> Dockerfile å®é™…è·¯å¾„ï¼‰
        2. ä¿®å¤ UNKNOWN èŠ‚ç‚¹ï¼ˆGGUF -> UNETLoaderï¼‰
        3. ä¿®å¤æ— æ•ˆçš„è°ƒåº¦å™¨åç§°ï¼ˆbeta57 -> normalï¼‰
        """
        # è°ƒåº¦å™¨åç§°æ˜ å°„ï¼šå°†æ— æ•ˆçš„è°ƒåº¦å™¨åç§°æ˜ å°„åˆ°æœ‰æ•ˆçš„åç§°
        scheduler_name_mapping = {
            "beta57": "normal",  # beta57 å¯èƒ½ä¸è¢«æ”¯æŒï¼Œä½¿ç”¨ normal æ›¿ä»£
        }
        
        for node_id, node_data in prompt_data.items():
            if not isinstance(node_data, dict):
                continue
            
            # 1. ä¿®å¤ UNKNOWN èŠ‚ç‚¹ï¼ˆåœ¨ queue_prompt_via_websocket ä¹‹å‰ä¿®å¤ï¼‰
            if "class_type" not in node_data:
                if "inputs" in node_data and "UNKNOWN" in node_data.get("inputs", {}):
                    unknown_value = node_data["inputs"]["UNKNOWN"]
                    logger.warning(f"Node {node_id} has UNKNOWN field: {unknown_value}")
                    
                    # å°è¯•ä¿®å¤ï¼šå¦‚æœæ˜¯ GGUF æ¨¡å‹æ–‡ä»¶ï¼Œè½¬æ¢ä¸º UNETLoader
                    if isinstance(unknown_value, str) and unknown_value.endswith(".gguf"):
                        logger.info(f"Fixing node {node_id}: converting UNKNOWN GGUF to UNETLoader")
                        node_data["class_type"] = "UNETLoader"
                        # å°† GGUF æ–‡ä»¶åè½¬æ¢ä¸º safetensors æ–‡ä»¶å
                        if "Qwen-Image-Edit-2509" in unknown_value:
                            node_data["inputs"] = {
                                "unet_name": "qwen_image_edit_2509_fp8_e4m3fn.safetensors",
                                "weight_dtype": "default"
                            }
                            logger.info(f"âœ… Fixed node {node_id}: UNETLoader with unet_name=qwen_image_edit_2509_fp8_e4m3fn.safetensors")
                        else:
                            # å…¶ä»– GGUF æ–‡ä»¶ï¼Œå°è¯•é€šç”¨è½¬æ¢
                            safetensors_name = unknown_value.replace(".gguf", ".safetensors").replace("-", "_").lower()
                            node_data["inputs"] = {
                                "unet_name": safetensors_name,
                                "weight_dtype": "default"
                            }
                            logger.warning(f"Fixed node {node_id} with guessed safetensors name: {safetensors_name}")
            
            # 2. ä¿®å¤ LoRA è·¯å¾„æ˜ å°„
            if "inputs" in node_data:
                inputs = node_data["inputs"]
                
                # ä¿®å¤ LoRA è·¯å¾„
                if "lora_name" in inputs:
                    lora_name = inputs["lora_name"]
                    # æ˜ å°„ï¼šqwen/Qwen-Image-Edit-2509-Lightning-4steps-V1.0-fp32.safetensors
                    #   -> Qwen-Image-Lightning-4steps-V1.0.safetensors
                    if lora_name == "qwen/Qwen-Image-Edit-2509-Lightning-4steps-V1.0-fp32.safetensors":
                        inputs["lora_name"] = "Qwen-Image-Lightning-4steps-V1.0.safetensors"
                        logger.info(f"âœ… Fixed LoRA path in node {node_id}: {lora_name} -> Qwen-Image-Lightning-4steps-V1.0.safetensors")
                
                # 3. ä¿®å¤æ— æ•ˆçš„è°ƒåº¦å™¨åç§°
                if "scheduler" in inputs:
                    scheduler_name = inputs["scheduler"]
                    if scheduler_name in scheduler_name_mapping:
                        new_scheduler = scheduler_name_mapping[scheduler_name]
                        inputs["scheduler"] = new_scheduler
                        logger.info(f"âœ… Fixed scheduler name in node {node_id}: {scheduler_name} -> {new_scheduler}")
    
    # ä¿®å¤æ¨¡å‹è·¯å¾„å’ŒèŠ‚ç‚¹
    fix_model_paths_and_nodes(prompt)
    
    # ------------------------------
    # å‚æ•°æ³¨å…¥ï¼ˆåªä¿®æ”¹ API Prompt çš„ inputsï¼‰
    # ------------------------------
    if workflow_type == "head_swap_v3":
        # Head Swap V3 workflow çš„å‚æ•°æ³¨å…¥
        # æ ¹æ®å¯¼å‡ºçš„ API Prompt æ¨¡æ¿è¿›è¡Œå‚æ•°æ³¨å…¥
        
        # 343: LoadImage (Body Reference)
        if "343" in prompt and image1_path:
            prompt["343"]["inputs"]["image"] = image1_path
        
        # 349: LoadImage (Face Reference)
        if "349" in prompt and image2_path:
            prompt["349"]["inputs"]["image"] = image2_path
        
        # 348: TextEncodeQwenImageEditPlus (prompt)
        if "348" in prompt:
            prompt["348"]["inputs"]["prompt"] = job_input.get(
                "prompt", 
                "head_swap: start with Picture 1 as the base image, keeping its lighting, environment, and background. remove the head from Picture 1 completely and replace it with the head from Picture 2. ensure the head and body have correct anatomical proportions, and blend the skin tones, shadows, and lighting naturally so the final result appears as one coherent, realistic person."
            )
        
        # 395: SamplerCustom (seed)
        if "395" in prompt:
            prompt["395"]["inputs"]["noise_seed"] = job_input.get("seed", 43)
        
        # 406: ImageResizeKJv2 (Body image resize)
        # æ³¨æ„ï¼šèŠ‚ç‚¹ 345 (EmptySD3LatentImage) çš„ width/height æ˜¯ä»èŠ‚ç‚¹ 406 è¿æ¥çš„
        # æ‰€ä»¥åªéœ€è¦ä¿®æ”¹ 406 çš„ width/heightï¼Œ345 ä¼šè‡ªåŠ¨ä½¿ç”¨
        if "406" in prompt:
            width = job_input.get("width", 1328)
            height = job_input.get("height", 1328)
            prompt["406"]["inputs"]["width"] = width
            prompt["406"]["inputs"]["height"] = height
        
        # 405: ImageResizeKJv2 (Face image resize)
        # å¦‚æœéœ€è¦è°ƒæ•´ Face å›¾ç‰‡çš„å°ºå¯¸ï¼Œä¹Ÿå¯ä»¥ä¿®æ”¹è¿™ä¸ªèŠ‚ç‚¹
        if "405" in prompt:
            # é»˜è®¤ä½¿ç”¨å’Œ Body å›¾ç‰‡ç›¸åŒçš„å°ºå¯¸
            width = job_input.get("width", 1328)
            height = job_input.get("height", 1328)
            prompt["405"]["inputs"]["width"] = width
            prompt["405"]["inputs"]["height"] = height
        
        # æ³¨æ„ï¼šèŠ‚ç‚¹ 345 (EmptySD3LatentImage) çš„ width/height æ˜¯ä»èŠ‚ç‚¹ 406 è¿æ¥çš„
        # æ ¼å¼ï¼š["406", 1] å’Œ ["406", 2]
        # æ‰€ä»¥ä¸éœ€è¦ç›´æ¥ä¿®æ”¹ 345 çš„ width/heightï¼Œå®ƒä»¬ä¼šè‡ªåŠ¨ä» 406 è·å–
    else:
        # é»˜è®¤ workflow çš„å‚æ•°æ³¨å…¥
        # æ³¨æ„ï¼šè¿™äº› node_id éœ€è¦æ ¹æ®å®é™…å¯¼å‡ºçš„ API Prompt è°ƒæ•´
        if "78" in prompt and image1_path:
            prompt["78"]["inputs"]["image"] = image1_path
        if "123" in prompt and image2_path:
            prompt["123"]["inputs"]["image"] = image2_path
        if "111" in prompt:
            prompt["111"]["inputs"]["prompt"] = job_input.get("prompt", "")
        if "3" in prompt:
            prompt["3"]["inputs"]["seed"] = job_input.get("seed", 954812286882415)
        if "128" in prompt:
            prompt["128"]["inputs"]["value"] = job_input.get("width", 720)
        if "129" in prompt:
            prompt["129"]["inputs"]["value"] = job_input.get("height", 1280)

    ws_url = f"ws://{server_address}:8188/ws?clientId={client_id}"
    logger.info(f"Connecting to WebSocket: {ws_url}")
    
    # ë¨¼ì € HTTP ì—°ê²°ì´ ê°€ëŠ¥í•œì§€ í™•ì¸
    http_url = f"http://{server_address}:8188/"
    logger.info(f"Checking HTTP connection to: {http_url}")
    
    # HTTP ì—°ê²° í™•ì¸ (ìµœëŒ€ 1ë¶„)
    max_http_attempts = 180
    for http_attempt in range(max_http_attempts):
        try:
            import urllib.request
            response = urllib.request.urlopen(http_url, timeout=5)
            logger.info(f"HTTP ì—°ê²° ì„±ê³µ (ì‹œë„ {http_attempt+1})")
            break
        except Exception as e:
            logger.warning(f"HTTP ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {http_attempt+1}/{max_http_attempts}): {e}")
            if http_attempt == max_http_attempts - 1:
                raise Exception("ComfyUI ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì„œë²„ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”.")
            time.sleep(1)
    
    ws = websocket.WebSocket()
    # ì›¹ì†Œì¼“ ì—°ê²° ì‹œë„ (ìµœëŒ€ 3ë¶„)
    max_attempts = int(180/5)  # 3ë¶„ (1ì´ˆì— í•œ ë²ˆì”© ì‹œë„)
    for attempt in range(max_attempts):
        try:
            ws.connect(ws_url)
            logger.info(f"ì›¹ì†Œì¼“ ì—°ê²° ì„±ê³µ (ì‹œë„ {attempt+1})")
            break
        except Exception as e:
            logger.warning(f"ì›¹ì†Œì¼“ ì—°ê²° ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_attempts}): {e}")
            if attempt == max_attempts - 1:
                raise Exception("ì›¹ì†Œì¼“ ì—°ê²° ì‹œê°„ ì´ˆê³¼ (3ë¶„)")
            time.sleep(5)
    images = get_images(ws, prompt)
    ws.close()

    # ì´ë¯¸ì§€ê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
    if not images:
        return {"error": "ì´ë¯¸ì§€ë¥¼ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
    
    # ì²« ë²ˆì§¸ ì´ë¯¸ì§€ ë°˜í™˜
    for node_id in images:
        if images[node_id]:
            return {"image": images[node_id][0]}
    
    return {"error": "ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

runpod.serverless.start({"handler": handler})